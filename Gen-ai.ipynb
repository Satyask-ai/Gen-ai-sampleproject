{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f595593-18a6-4fc3-ab5a-41a2de9b6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb99589-fb2d-4ad1-8b86-9364c753adb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303dfab6b90742c9a2b06ce2f39c285c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\.conda\\envs\\genai-env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\satya\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c324b5426b245429b3c5d19c530d925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2ba82976164ffd9adb970830c863bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d368fb3a174ee48a62c3afbb4a3b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39761c28db6845cdba99890c20f9e22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e5578c-d07e-4e5a-98ef-3e3c46828f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sentence\n",
    "text = \"Generative AI is transforming the world.\"\n",
    "\n",
    "# Tokenize text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids = torch.tensor([token_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8614f2c-65ac-4e4f-ac46-fab6c3e97ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = outputs.last_hidden_state[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740170ff-85b8-4a80-9522-89f49f523be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = outputs.last_hidden_state[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af04074e-4411-4cde-a78f-3292341a009f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>genera</th>\n",
       "      <td>0.181139</td>\n",
       "      <td>-0.078522</td>\n",
       "      <td>0.060165</td>\n",
       "      <td>0.787509</td>\n",
       "      <td>0.233013</td>\n",
       "      <td>-0.191161</td>\n",
       "      <td>-0.048425</td>\n",
       "      <td>0.181756</td>\n",
       "      <td>0.076007</td>\n",
       "      <td>-0.513294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028691</td>\n",
       "      <td>-0.387628</td>\n",
       "      <td>-0.123599</td>\n",
       "      <td>-0.531913</td>\n",
       "      <td>-0.502353</td>\n",
       "      <td>0.455861</td>\n",
       "      <td>0.096331</td>\n",
       "      <td>-0.136206</td>\n",
       "      <td>-0.392188</td>\n",
       "      <td>0.805392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>##tive</th>\n",
       "      <td>0.312030</td>\n",
       "      <td>0.301407</td>\n",
       "      <td>-0.123590</td>\n",
       "      <td>0.599827</td>\n",
       "      <td>0.454752</td>\n",
       "      <td>0.105675</td>\n",
       "      <td>-0.123649</td>\n",
       "      <td>0.182938</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>-0.622368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>-0.209057</td>\n",
       "      <td>-0.209255</td>\n",
       "      <td>-0.351102</td>\n",
       "      <td>-0.527964</td>\n",
       "      <td>0.617454</td>\n",
       "      <td>-0.232249</td>\n",
       "      <td>-0.474786</td>\n",
       "      <td>-0.150052</td>\n",
       "      <td>0.478080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>0.258419</td>\n",
       "      <td>0.290816</td>\n",
       "      <td>0.048777</td>\n",
       "      <td>0.695664</td>\n",
       "      <td>0.578393</td>\n",
       "      <td>0.105390</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.344261</td>\n",
       "      <td>-0.058039</td>\n",
       "      <td>-0.355309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308181</td>\n",
       "      <td>-0.457336</td>\n",
       "      <td>-0.224176</td>\n",
       "      <td>-0.571063</td>\n",
       "      <td>-0.415991</td>\n",
       "      <td>0.770859</td>\n",
       "      <td>0.033219</td>\n",
       "      <td>-0.544990</td>\n",
       "      <td>-0.319195</td>\n",
       "      <td>0.620034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.309880</td>\n",
       "      <td>0.102927</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>0.526486</td>\n",
       "      <td>0.307353</td>\n",
       "      <td>0.140098</td>\n",
       "      <td>-0.130312</td>\n",
       "      <td>0.494972</td>\n",
       "      <td>-0.146889</td>\n",
       "      <td>-0.791137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340313</td>\n",
       "      <td>-0.243358</td>\n",
       "      <td>-0.001579</td>\n",
       "      <td>-0.523469</td>\n",
       "      <td>-0.265432</td>\n",
       "      <td>0.527702</td>\n",
       "      <td>0.282528</td>\n",
       "      <td>-0.351354</td>\n",
       "      <td>-0.267957</td>\n",
       "      <td>0.802517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transforming</th>\n",
       "      <td>0.238191</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>0.156727</td>\n",
       "      <td>0.548129</td>\n",
       "      <td>0.379564</td>\n",
       "      <td>-0.105301</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.366573</td>\n",
       "      <td>-0.210387</td>\n",
       "      <td>-0.643820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502330</td>\n",
       "      <td>-0.076133</td>\n",
       "      <td>-0.113381</td>\n",
       "      <td>-0.491341</td>\n",
       "      <td>-0.298082</td>\n",
       "      <td>0.336718</td>\n",
       "      <td>0.096105</td>\n",
       "      <td>-0.670696</td>\n",
       "      <td>-0.289046</td>\n",
       "      <td>0.414651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5    \\\n",
       "genera        0.181139 -0.078522  0.060165  0.787509  0.233013 -0.191161   \n",
       "##tive        0.312030  0.301407 -0.123590  0.599827  0.454752  0.105675   \n",
       "ai            0.258419  0.290816  0.048777  0.695664  0.578393  0.105390   \n",
       "is           -0.309880  0.102927 -0.005865  0.526486  0.307353  0.140098   \n",
       "transforming  0.238191  0.009944  0.156727  0.548129  0.379564 -0.105301   \n",
       "\n",
       "                   6         7         8         9    ...       758       759  \\\n",
       "genera       -0.048425  0.181756  0.076007 -0.513294  ... -0.028691 -0.387628   \n",
       "##tive       -0.123649  0.182938  0.032985 -0.622368  ...  0.004375 -0.209057   \n",
       "ai            0.036683  0.344261 -0.058039 -0.355309  ... -0.308181 -0.457336   \n",
       "is           -0.130312  0.494972 -0.146889 -0.791137  ... -0.340313 -0.243358   \n",
       "transforming  0.114500  0.366573 -0.210387 -0.643820  ... -0.502330 -0.076133   \n",
       "\n",
       "                   760       761       762       763       764       765  \\\n",
       "genera       -0.123599 -0.531913 -0.502353  0.455861  0.096331 -0.136206   \n",
       "##tive       -0.209255 -0.351102 -0.527964  0.617454 -0.232249 -0.474786   \n",
       "ai           -0.224176 -0.571063 -0.415991  0.770859  0.033219 -0.544990   \n",
       "is           -0.001579 -0.523469 -0.265432  0.527702  0.282528 -0.351354   \n",
       "transforming -0.113381 -0.491341 -0.298082  0.336718  0.096105 -0.670696   \n",
       "\n",
       "                   766       767  \n",
       "genera       -0.392188  0.805392  \n",
       "##tive       -0.150052  0.478080  \n",
       "ai           -0.319195  0.620034  \n",
       "is           -0.267957  0.802517  \n",
       "transforming -0.289046  0.414651  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df = pd.DataFrame(embeddings.numpy(), index=tokens)\n",
    "embedding_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80d51b-eaae-4eb9-9e26-b8752f839534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
